#                                                                      ุจู ูุงู ุฎุฏุง                                                                  
# install: pip install --upgrade arabic-reshaper
import arabic_reshaper
#-------------------------------------------------------
# install: pip install python-bidi
from bidi.algorithm import get_display
#-------------------------------------------------------

from transformers import AutoTokenizer, AutoModelForSeq2SeqLM

# ุชูุธูุงุช ููุงุด ูุงุฑุณ
def fa(text):
    return get_display(arabic_reshaper.reshape(text))

# ==================================================================================
#                                       ุงุณุชูุงุฏู ุงุฒ ูุฏู ูุง ูุฎุตูุต ูุงุฑุณ                             
# ==================================================================================

class PersianSummarizer:
    def __init__(self):
        # ุงุณุชูุงุฏู ุงุฒ ูุฏู ููุงุณุจ ุจุฑุง ุฎูุงุตูโุณุงุฒ ูุงุฑุณ
        self.model_name = "google/mt5-small"
        # m3hrdadfi/mt5-small-persian-summarization
        # ุง ุงุฒ ุงู ูุฏู ุงุณุชูุงุฏู ฺฉูุฏ: "google/mt5-small"
        
        try:
            print(fa("๐ฅ ุฏุฑ ุญุงู ุจุงุฑฺฏุฐุงุฑ ูุฏู ุฎูุงุตูโุณุงุฒ..."))
            self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)
            self.model = AutoModelForSeq2SeqLM.from_pretrained(self.model_name)
            print(fa("โ ูุฏู ุจุง ููููุช ุจุงุฑฺฏุฐุงุฑ ุดุฏ"))
        except Exception as e:
            print(fa(f"โ ุฎุทุง ุฏุฑ ุจุงุฑฺฏุฐุงุฑ ูุฏู: {e}"))
            print(fa("๐ง ุฏุฑ ุญุงู ุงุณุชูุงุฏู ุงุฒ ูุฏู ุฌุงฺฏุฒู..."))
            self.model_name = "google/mt5-small"
            self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)
            self.model = AutoModelForSeq2SeqLM.from_pretrained(self.model_name)
    
    def summarize(self, text, max_length=150, min_length=40):
        try:
            # ุงุถุงูู ฺฉุฑุฏู ูพุดููุฏ ุจุฑุง ุฎูุงุตูโุณุงุฒ
            if "mt5" in self.model_name.lower():
                input_text = "ุฎูุงุตู ฺฉู: " + text
            else:
                input_text = "summarize: " + text
            
            # ุชูฺฉูุงุฒ ฺฉุฑุฏู ูุชู ูุฑูุฏ
            inputs = self.tokenizer(
                input_text,
                return_tensors="pt",
                max_length=512,
                truncation=True,
                padding="max_length"
            )
            
            # ุชููุฏ ุฎูุงุตู
            outputs = self.model.generate(
                inputs["input_ids"],
                max_length=max_length,
                min_length=min_length,
                num_beams=4,
                early_stopping=True,
                repetition_penalty=2.0,
                length_penalty=1.0,
                no_repeat_ngram_size=3
            )
            
            # ุฏฺฉุฏ ฺฉุฑุฏู ุฎุฑูุฌ
            summary = self.tokenizer.decode(outputs[0], skip_special_tokens=True)
            return summary
            
        except Exception as e:
            return fa(f"ุฎุทุง ุฏุฑ ุฎูุงุตูโุณุงุฒ: {str(e)}")

# ุชุณุช ุจุง ูุชู ุทููุงูโุชุฑ
persian_text = """
ููุด ูุตููุน ุฏุฑ ุญุงู ุชุญูู ุตูุนุช ูพุฒุดฺฉ ุงุณุช. ูพุดุฑูุชโูุง ุงุฎุฑ ุฏุฑ ุงูฺฏูุฑุชูโูุง ุงุฏฺฏุฑ ูุงุดู 
ุชูุงูุง ฺฉุงููพูุชุฑูุง ุฑุง ุฏุฑ ุชุญูู ุชุตุงูุฑ ูพุฒุดฺฉ ุจุง ุฏูุช ูุฑุงุชุฑ ุงุฒ ูุชุฎุตุตุงู ุงูุณุงู ูุฑุงูู ฺฉุฑุฏู ุงุณุช. 
ุฏุฑ ุฑุงุฏูููฺุ ุณุณุชูโูุง ููุด ูุตููุน ูโุชูุงููุฏ ุนูุงุฆู ุงููู ุจูุงุฑโูุง ูุงููุฏ ุณุฑุทุงู ุฑุง ุฏุฑ 
ุนฺฉุณโูุง ุงุดุนู ุงฺฉุณ ู ุงุณฺฉู MRI ุชุดุฎุต ุฏููุฏ. ุงู ุณุณุชูโูุง ูุงุฏุฑูุฏ ุงูฺฏููุง ุฑุง ุดูุงุณุง ฺฉููุฏ 
ฺฉู ุญุช ุจุฑุง ฺุดู ุงูุณุงู ูุงุจู ูุดุงูุฏู ูุณุชูุฏ. ุฏุฑ ูพุงุชูููฺุ ููุด ูุตููุน ุฏุฑ ุชุญูู ูููููโูุง ุจุงูุช 
ู ุดูุงุณุง ูุงููุฌุงุฑโูุง ฺฉูฺฉ ูโฺฉูุฏ. ุนูุงูู ุจุฑ ุชุตูุฑุจุฑุฏุงุฑ ูพุฒุดฺฉุ ููุด ูุตููุน ุฏุฑ ุญุงู 
ุชุญูู ฺฉุดู ุฏุงุฑููุง ุจุง ูพุดโุจู ูุญูู ุชุนุงูู ูููฺฉููโูุง ู ุดูุงุณุง ุฏุฑูุงูโูุง ุจุงูููู ุฌุฏุฏ ุงุณุช.
ุงู ููุงูุฑ ูโุชูุงูุฏ ุฒูุงู ู ูุฒูู ููุฑุฏ ูุงุฒ ุจุฑุง ุชูุณุนู ุฏุงุฑููุง ุฌุฏุฏ ุฑุง ุจู ูุฒุงู ูุงุจู ุชูุฌู ฺฉุงูุด ุฏูุฏ.
ููฺูู ุฏุฑ ุฒููู ูพุฒุดฺฉ ุดุฎุตุ ููุด ูุตููุน ูโุชูุงูุฏ ุฏุฑูุงูโูุง ุณูุงุฑุด ุจุฑ ุงุณุงุณ ฺูุชฺฉ ู 
ุณูุงุจู ูพุฒุดฺฉ ูุฑ ุจูุงุฑ ุงุฑุงุฆู ุฏูุฏ.
"""

summarizer = PersianSummarizer()
summary = summarizer.summarize(persian_text, max_length=100, min_length=30)

print(fa("๐ ูุชู ุงุตู:"))
print(fa(persian_text))
print(fa("\n๐ ุฎูุงุตู ูุงุฑุณ:"))
print(fa(summary))