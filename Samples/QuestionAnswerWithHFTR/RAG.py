#                                                                     Ø¨Ù‡ Ù†Ø§Ù… Ø®Ø¯Ø§
# install: pip install --upgrade arabic-reshaper
import arabic_reshaper
#-------------------------------------------------------
# install: pip install python-bidi
from bidi.algorithm import get_display
#-------------------------------------------------------

from transformers import pipeline, AutoTokenizer, AutoModel
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np
import torch

# ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù†Ù…Ø§ÛŒØ´ ÙØ§Ø±Ø³ÛŒ
def fa(text):
    return get_display(arabic_reshaper.reshape(text))

# ====================================================================================
#  Ø³ÛŒØ³ØªÙ… RAG (Retrieval-Augmented Generation)
# ====================================================================================

from transformers import pipeline, AutoTokenizer, AutoModel
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np

class RAGSystem:
    def __init__(self):
        # Ù…Ø¯Ù„ Ø¨Ø±Ø§ÛŒ embeddings
        self.tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')
        self.model = AutoModel.from_pretrained('sentence-transformers/paraphrase-MiniLM-L12-v2')
        
        # Ù…Ø¯Ù„ Ø¨Ø±Ø§ÛŒ ØªÙˆÙ„ÛŒØ¯ Ù¾Ø§Ø³Ø®
        self.generator = pipeline(
            "text2text-generation",
            model="google/mt5-small",
            tokenizer="google/mt5-small"
        )
        
        self.documents = []
        self.embeddings = []
    
    def add_documents(self, texts):
        """Ø§ÙØ²ÙˆØ¯Ù† Ø§Ø³Ù†Ø§Ø¯ Ø¨Ù‡ Ø³ÛŒØ³ØªÙ…"""
        self.documents.extend(texts)
        
        # Ø§ÛŒØ¬Ø§Ø¯ embeddings Ø¨Ø±Ø§ÛŒ Ø§Ø³Ù†Ø§Ø¯
        for text in texts:
            inputs = self.tokenizer(text, return_tensors='pt', truncation=True, padding=True, max_length=512)
            with torch.no_grad():
                outputs = self.model(**inputs)
            embedding = outputs.last_hidden_state.mean(dim=1).numpy()
            self.embeddings.append(embedding)
    
    def find_relevant_docs(self, question, top_k=3):
        """Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† Ù…Ø±ØªØ¨Ø·â€ŒØªØ±ÛŒÙ† Ø§Ø³Ù†Ø§Ø¯"""
        # Ø§ÛŒØ¬Ø§Ø¯ embedding Ø¨Ø±Ø§ÛŒ Ø³ÙˆØ§Ù„
        inputs = self.tokenizer(question, return_tensors='pt', truncation=True, padding=True, max_length=512)
        with torch.no_grad():
            outputs = self.model(**inputs)
        question_embedding = outputs.last_hidden_state.mean(dim=1).numpy()
        
        # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø´Ø¨Ø§Ù‡Øª
        similarities = []
        for doc_embedding in self.embeddings:
            similarity = cosine_similarity(question_embedding, doc_embedding)[0][0]
            similarities.append(similarity)
        
        # Ø§Ù†ØªØ®Ø§Ø¨ Ø¨Ù‡ØªØ±ÛŒÙ† Ø§Ø³Ù†Ø§Ø¯
        best_indices = np.argsort(similarities)[-top_k:][::-1]
        return [self.documents[i] for i in best_indices]
    
    def answer_question(self, question):
        """Ù¾Ø§Ø³Ø® Ø¨Ù‡ Ø³ÙˆØ§Ù„ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø§Ø³Ù†Ø§Ø¯"""
        relevant_docs = self.find_relevant_docs(question)
        context = " ".join(relevant_docs)
        
        prompt = f"Ø¨Ø± Ø§Ø³Ø§Ø³ Ù…ØªÙ† Ø²ÛŒØ± Ø¨Ù‡ Ø³ÙˆØ§Ù„ Ù¾Ø§Ø³Ø® Ø¯Ù‡ÛŒØ¯:\n{context}\n\nØ³ÙˆØ§Ù„: {question}\nÙ¾Ø§Ø³Ø®:"
        
        response = self.generator(
            prompt,
            max_length=200,
            num_return_sequences=1,
            temperature=0.7
        )
        
        return response[0]['generated_text']

# Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø³ÛŒØ³ØªÙ… RAG
rag = RAGSystem()

# Ø§ÙØ²ÙˆØ¯Ù† Ø§Ø³Ù†Ø§Ø¯ Ù…Ø®ØªÙ„Ù
documents = [
    "Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ø¨Ù‡ Ù…Ø§Ø´ÛŒÙ†â€ŒÙ‡Ø§ ØªÙˆØ§Ù†Ø§ÛŒÛŒ ÙÚ©Ø± Ú©Ø±Ø¯Ù† Ùˆ ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ù…ÛŒâ€ŒØ¯Ù‡Ø¯.",
    "ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ø¹Ù…ÛŒÙ‚ Ø§Ø² Ø´Ø¨Ú©Ù‡â€ŒÙ‡Ø§ÛŒ Ø¹ØµØ¨ÛŒ Ù…ØµÙ†ÙˆØ¹ÛŒ Ø¨Ø§ Ù„Ø§ÛŒÙ‡â€ŒÙ‡Ø§ÛŒ Ø²ÛŒØ§Ø¯ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯.",
    "ØªØ±Ø§Ù†Ø³ÙÙˆØ±Ù…Ø±Ù‡Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø²Ø¨Ø§Ù† Ø·Ø¨ÛŒØ¹ÛŒ Ø§Ù†Ù‚Ù„Ø§Ø¨ Ø§ÛŒØ¬Ø§Ø¯ Ú©Ø±Ø¯Ù‡â€ŒØ§Ù†Ø¯.",
    "Hugging Face Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ transformer Ø§Ø³Øª.",
    "BERT Ù…Ø¯Ù„ÛŒ Ø¨Ø±Ø§ÛŒ ÙÙ‡Ù… Ø²Ø¨Ø§Ù† Ø§Ø³Øª Ú©Ù‡ ØªÙˆØ³Ø· Ú¯ÙˆÚ¯Ù„ ØªÙˆØ³Ø¹Ù‡ ÛŒØ§ÙØªÙ‡."
]

rag.add_documents(documents)

# Ù¾Ø±Ø³Ø´ Ø³ÙˆØ§Ù„Ø§Øª
questions = [
    "Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ú†ÛŒØ³ØªØŸ",
    "ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ø¹Ù…ÛŒÙ‚ Ú†Ù‡ ÙˆÛŒÚ˜Ú¯ÛŒ Ø¯Ø§Ø±Ø¯ØŸ",
    "Hugging Face Ú†ÛŒØ³ØªØŸ",
    "BERT ØªÙˆØ³Ø· Ú†Ù‡ Ø´Ø±Ú©ØªÛŒ Ø³Ø§Ø®ØªÙ‡ Ø´Ø¯Ù‡ØŸ"
]

for q in questions:
    answer = rag.answer_question(q)
    print(fa(f"â“ {q}"))
    print(fa(f"ğŸ’¡ {answer}\n"))