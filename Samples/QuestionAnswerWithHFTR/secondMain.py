#                                                                        Ø¨Ù‡ Ù†Ø§Ù… Ø®Ø¯Ø§
# install: pip install --upgrade arabic-reshaper
import arabic_reshaper
#-------------------------------------------------------
# install: pip install python-bidi
from bidi.algorithm import get_display
#-------------------------------------------------------
from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline
import torch

# ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù†Ù…Ø§ÛŒØ´ ÙØ§Ø±Ø³ÛŒ
def fa(text):
    return get_display(arabic_reshaper.reshape(text))

#============================================================================
#  Ú†Øª Ø¨Ø§Øª Ù‡ÙˆØ´Ù…Ù†Ø¯ Ø¨Ø§ Ø­Ø§ÙØ¸Ù‡
#============================================================================

class SmartChatbot:
    def __init__(self):
        self.conversation_history = []
        
        # Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„ Ú¯ÙØªÚ¯Ùˆ
        self.chat_pipeline = pipeline(
            "text-generation",
            model="microsoft/DialoGPT-medium",
            tokenizer="microsoft/DialoGPT-medium"
        )
    
    def add_context(self, context_text):
        """Ø§ÙØ²ÙˆØ¯Ù† Ù…ØªÙ† Ø²Ù…ÛŒÙ†Ù‡ Ø¨Ù‡ Ø­Ø§ÙØ¸Ù‡"""
        self.conversation_history.append(f"Ù…ØªÙ† Ø²Ù…ÛŒÙ†Ù‡: {context_text}")
    
    def ask_question(self, question):
        """Ù¾Ø±Ø³Ø´ Ø³ÙˆØ§Ù„ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø²Ù…ÛŒÙ†Ù‡"""
        # Ø³Ø§Ø®Øª prompt Ø§Ø² ØªØ§Ø±ÛŒØ®Ú†Ù‡ Ùˆ Ø³ÙˆØ§Ù„ Ø¬Ø¯ÛŒØ¯
        prompt = "\n".join(self.conversation_history) + f"\nØ³ÙˆØ§Ù„: {question}\nÙ¾Ø§Ø³Ø®:"
        
        # ØªÙˆÙ„ÛŒØ¯ Ù¾Ø§Ø³Ø®
        response = self.chat_pipeline(
            prompt,
            max_length=200,
            num_return_sequences=1,
            temperature=0.7,
            pad_token_id=50256
        )
        
        answer = response[0]['generated_text'].split("Ù¾Ø§Ø³Ø®:")[-1].strip()
        
        # Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± ØªØ§Ø±ÛŒØ®Ú†Ù‡
        self.conversation_history.append(f"Ø³ÙˆØ§Ù„: {question}")
        self.conversation_history.append(f"Ù¾Ø§Ø³Ø®: {answer}")
        
        return answer

# Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ú†Øª Ø¨Ø§Øª
bot = SmartChatbot()

# Ø§ÙØ²ÙˆØ¯Ù† Ù…ØªÙ† Ø²Ù…ÛŒÙ†Ù‡
context = """
Ø´Ø±Ú©Øª Ù…Ø§ Ø¯Ø± Ø²Ù…ÛŒÙ†Ù‡ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ ÙØ¹Ø§Ù„ÛŒØª Ù…ÛŒâ€ŒÚ©Ù†Ø¯. 
Ù…Ø§ Ù…Ø­ØµÙˆÙ„Ø§Øª Ù…ØªÙ†ÙˆØ¹ÛŒ Ø¯Ø§Ø±ÛŒÙ… Ø§Ø² Ø¬Ù…Ù„Ù‡ Ø¯Ø³ØªÛŒØ§Ø± ØµÙˆØªÛŒØŒ Ø³ÛŒØ³ØªÙ… Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ø¯Ù‡Ù†Ø¯Ù‡ Ùˆ ØªØ­Ù„ÛŒÙ„ Ø§Ø­Ø³Ø§Ø³Ø§Øª.
ØªÛŒÙ… Ù…Ø§ Ù…ØªØ´Ú©Ù„ Ø§Ø² Û±Û° Ù…Ù‡Ù†Ø¯Ø³ Ø¯Ø§Ø¯Ù‡ Ùˆ Ûµ Ù…ØªØ®ØµØµ ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ù…Ø§Ø´ÛŒÙ† Ø§Ø³Øª.
"""

bot.add_context(context)

# Ù¾Ø±Ø³Ø´ Ø³ÙˆØ§Ù„Ø§Øª
questions = [
    "Ø´Ø±Ú©Øª Ø´Ù…Ø§ Ú†Ù‡ Ú©Ø§Ø±ÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ø¯ØŸ",
    "ØªØ¹Ø¯Ø§Ø¯ Ú©Ø§Ø±Ù…Ù†Ø¯Ø§Ù† Ø´Ù…Ø§ Ú†Ù‚Ø¯Ø± Ø§Ø³ØªØŸ",
    "Ú†Ù‡ Ù…Ø­ØµÙˆÙ„Ø§ØªÛŒ Ø§Ø±Ø§Ø¦Ù‡ Ù…ÛŒâ€ŒØ¯Ù‡ÛŒØ¯ØŸ"
]

for q in questions:
    answer = bot.ask_question(q)
    print(fa(f"ğŸ‘¤: {q}"))
    print(fa(f"ğŸ¤–: {answer}\n"))